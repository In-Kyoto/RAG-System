import streamlit as st
import lancedb
from sentence_transformers import SentenceTransformer
import requests
from PIL import Image
from io import BytesIO

API_KEY = st.secrets["GROQ_API_KEY"]
got_result = True

st.set_page_config(page_title="Multimodal RAG", layout="wide")
st.title("Multimodal RAG System")


def get_answer_from_llama(query, context):
    url = "https://api.groq.com/openai/v1/chat/completions"
    model = "llama-3.1-8b-instant"
    max_tokens = 512

    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": """
                Ð¢Ð¸ â€” ÐºÐ¾Ñ€Ð¸ÑÐ½Ð¸Ð¹ Ð°ÑÐ¸ÑÑ‚ÐµÐ½Ñ‚-ÐµÐºÑÐ¿ÐµÑ€Ñ‚ Ð· ÑƒÐºÑ€Ð°Ñ—Ð½ÑÑŒÐºÐ¸Ñ… Ð½Ð¾Ð²Ð¸Ð½.
                Ð’Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð°Ð¹ Ð¢Ð†Ð›Ð¬ÐšÐ˜ ÑƒÐºÑ€Ð°Ñ—Ð½ÑÑŒÐºÐ¾ÑŽ Ð¼Ð¾Ð²Ð¾ÑŽ.
                
                ÐŸÑ€Ð°Ð²Ð¸Ð»Ð°:
                1. Ð”Ð°Ð¹ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÑƒ, Ð·Ñ€Ð¾Ð·ÑƒÐ¼Ñ–Ð»Ñƒ Ñ– Ð·Ð¼Ñ–ÑÑ‚Ð¾Ð²Ð½Ñƒ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÑŒ (Ð¼Ð°ÐºÑÐ¸Ð¼ÑƒÐ¼ 150â€“200 ÑÐ»Ñ–Ð²).
                2. Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ¹ Ñ‚Ñ–Ð»ÑŒÐºÐ¸ Ñ–Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ñ–ÑŽ Ð· Ð½Ð°Ð´Ð°Ð½Ð¾Ð³Ð¾ Ð½Ð¸Ð¶Ñ‡Ðµ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ñƒ.
                3. Ð¯ÐºÑ‰Ð¾ Ð² ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ñ– Ð½ÐµÐ¼Ð°Ñ” Ð¿Ñ€ÑÐ¼Ð¾Ñ— Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ– Ð½Ð° Ð¿Ð¸Ñ‚Ð°Ð½Ð½Ñ Ð°Ð±Ð¾ Ñ–Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ñ–Ñ Ð²Ñ–Ð´ÑÑƒÑ‚Ð½Ñ/Ð½ÐµÑ‡Ñ–Ñ‚ÐºÐ° â€” Ð¾Ð±Ð¾Ð²â€™ÑÐ·ÐºÐ¾Ð²Ð¾ Ð½Ð°Ð¿Ð¸ÑˆÐ¸:
                   Â«Ð£ ÑÑ‚Ð°Ñ‚Ñ‚ÑÑ… Ð½ÐµÐ¼Ð°Ñ” Ñ–Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ñ–Ñ— Ð¿Ñ€Ð¾ Ñ†Ðµ.Â»
                   Ñ– Ð±Ñ–Ð»ÑŒÑˆÐµ Ð½Ñ–Ñ‡Ð¾Ð³Ð¾ Ð½Ðµ Ð´Ð¾Ð´Ð°Ð²Ð°Ð¹.
                4. ÐÑ–ÐºÐ¾Ð»Ð¸ Ð½Ðµ Ð²Ð¸Ð³Ð°Ð´ÑƒÐ¹ Ñ– Ð½Ðµ Ð´Ð¾Ð¼Ð¸ÑÐ»ÑŽÐ¹ Ñ„Ð°ÐºÑ‚Ð¸.
                """
            },
            {"role": "user", "content": f"ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚:\n{context}\n\nÐŸÐ¸Ñ‚Ð°Ð½Ð½Ñ: {query}"}

        ],
        "temperature": 0.6,
        "max_tokens": max_tokens
    }

    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }

    try:
        response = requests.post(url, json=payload, headers=headers, timeout=20)

        if response.status_code != 200:
            return f"Groq Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ° {response.status_code}: {response.text[:200]}"

        data = response.json()

        if "choices" in data and data["choices"]:
            return data["choices"][0]["message"]["content"].strip()

        return "ÐÐµÐ²Ñ–Ð´Ð¾Ð¼Ð¸Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ–"

    except Exception as e:
        return f"ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ°: {str(e)}"


@st.cache_resource
def get_db_and_model():
    db = lancedb.connect("./data/lancedb")
    table = db.open_table("the_batch")
    model = SentenceTransformer("all-MiniLM-L6-v2")

    return table, model


table, model = get_db_and_model()

query = st.chat_input("Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ð¿Ð¸Ñ‚Ð°Ð½Ð½Ñ...")

if query:
    with st.spinner("ðŸ” Ð¨ÑƒÐºÐ°ÑŽ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ñƒ ÑÑ‚Ð°Ñ‚Ñ‚ÑŽ..."):
        query_vec = model.encode(query).tolist()

        results = table.search(query_vec).limit(5).to_list()

        if not results:
            st.error("ÐÑ–Ñ‡Ð¾Ð³Ð¾ Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾")
            st.stop()


        best_article = min(results, key=lambda x: x.get("_distance", 1))

        title = best_article.get("title", "Ð‘ÐµÐ· Ð½Ð°Ð·Ð²Ð¸")
        text = best_article.get("text", "")
        images = best_article.get("images", [])[:3]
        url = best_article.get("url", "#")
        date = best_article.get("date", "ÐÐµÐ²Ñ–Ð´Ð¾Ð¼Ð° Ð´Ð°Ñ‚Ð°")
        score = round(1 - best_article.get("_distance", 1), 3)

        context = f"""
            ÐÐ°Ð·Ð²Ð°: {title}
            Ð”Ð°Ñ‚Ð°: {date}

            Ð¢ÐµÐºÑÑ‚ ÑÑ‚Ð°Ñ‚Ñ‚Ñ–:
            {text}
            """

        answer = get_answer_from_llama(query, context)

        if "Ð½ÐµÐ¼Ð°Ñ” Ñ–Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ñ–Ñ—" in answer.lower():
            got_result = False

    st.chat_message("user").write(query)
    st.chat_message("assistant").write(answer)


    if got_result:
        if images:
            st.subheader("ðŸ–¼ Ð—Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ Ð·Ñ– ÑÑ‚Ð°Ñ‚Ñ‚Ñ–")
            cols = st.columns(len(images))

            for i, img_url in enumerate(images):
                try:
                    response = requests.get(img_url, timeout=5)
                    img = Image.open(BytesIO(response.content))
                    cols[i].image(img, use_container_width=True, caption=title[:40])
                except:
                    cols[i].image(img_url, use_container_width=True)

        st.subheader("ðŸ“„ Ð”Ð¶ÐµÑ€ÐµÐ»Ð¾ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ–")
        st.markdown(f"**[{title}]({url})**")
        st.write(f"Ð”Ð°Ñ‚Ð°: {date}")
        st.write(f"Ð ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ñ–ÑÑ‚ÑŒ: {score * 100}%")

        with st.expander("ðŸ“– Ð§Ð¸Ñ‚Ð°Ñ‚Ð¸ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚ ÑÑ‚Ð°Ñ‚Ñ‚Ñ–"):
            st.write(text[:1000] + "..." if len(text) > 1000 else text)

    images = []
    got_result = True
    context = ""
    best_article = None
    results = []
