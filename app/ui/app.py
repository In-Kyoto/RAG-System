import streamlit as st
import lancedb
from sentence_transformers import SentenceTransformer
import requests
from PIL import Image
from io import BytesIO

API_KEY = st.secrets["GROQ_API_KEY"]
got_result = True

st.set_page_config(page_title="Multimodal RAG", layout="wide")
st.title("Multimodal RAG System")


def get_answer_from_llama(query, context):
    url = "https://api.groq.com/openai/v1/chat/completions"
    model = "llama-3.1-8b-instant"
    max_tokens = 512

    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": "Ð’Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð°Ð¹ Ð¢Ð†Ð›Ð¬ÐšÐ˜ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ñ– Ð½Ð°Ð´Ð°Ð½Ð¾Ð³Ð¾ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ñƒ. Ð¯ÐºÑ‰Ð¾ Ñƒ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ñ– Ð½ÐµÐ¼Ð°Ñ” Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ– â€” ÑÐºÐ°Ð¶Ð¸: 'Ð£ ÑÑ‚Ð°Ñ‚Ñ‚ÑÑ… Ð½ÐµÐ¼Ð°Ñ” Ñ–Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ñ–Ñ— Ð´Ð»Ñ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ– Ð½Ð° Ñ†Ðµ Ð¿Ð¸Ñ‚Ð°Ð½Ð½Ñ'."},
            {"role": "user", "content": f"ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚:\n{context}\n\nÐŸÐ¸Ñ‚Ð°Ð½Ð½Ñ: {query}"}

        ],
        "temperature": 0.6,
        "max_tokens": max_tokens
    }

    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }

    try:
        response = requests.post(url, json=payload, headers=headers, timeout=20)

        if response.status_code != 200:
            return f"Groq Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ° {response.status_code}: {response.text[:200]}"

        data = response.json()

        if "choices" in data and data["choices"]:
            return data["choices"][0]["message"]["content"].strip()

        return "ÐÐµÐ²Ñ–Ð´Ð¾Ð¼Ð¸Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ–"

    except Exception as e:
        return f"ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ°: {str(e)}"


@st.cache_resource
def get_db_and_model():
    db = lancedb.connect("./data/lancedb")
    table = db.open_table("the_batch")
    model = SentenceTransformer("all-MiniLM-L6-v2")

    return table, model


table, model = get_db_and_model()

query = st.chat_input("Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ð¿Ð¸Ñ‚Ð°Ð½Ð½Ñ...")

if query:
    with st.spinner("ðŸ” Ð¨ÑƒÐºÐ°ÑŽ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ñƒ ÑÑ‚Ð°Ñ‚Ñ‚ÑŽ..."):
        query_vec = model.encode(query).tolist()

        results = table.search(query_vec).limit(5).to_list()

        if not results:
            st.error("ÐÑ–Ñ‡Ð¾Ð³Ð¾ Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾")
            st.stop()


        best_article = min(results, key=lambda x: x.get("_distance", 1))

        title = best_article.get("title", "Ð‘ÐµÐ· Ð½Ð°Ð·Ð²Ð¸")
        text = best_article.get("text", "")
        images = best_article.get("images", [])[:3]
        url = best_article.get("url", "#")
        date = best_article.get("date", "ÐÐµÐ²Ñ–Ð´Ð¾Ð¼Ð° Ð´Ð°Ñ‚Ð°")
        score = round(1 - best_article.get("_distance", 1), 3)

        context = f"""
            ÐÐ°Ð·Ð²Ð°: {title}
            Ð”Ð°Ñ‚Ð°: {date}

            Ð¢ÐµÐºÑÑ‚ ÑÑ‚Ð°Ñ‚Ñ‚Ñ–:
            {text}
            """

        answer = get_answer_from_llama(query, context)

        if "Ð½ÐµÐ¼Ð°Ñ” Ñ–Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ñ–Ñ—" in answer.lower():
            got_result = False

    st.chat_message("user").write(query)
    st.chat_message("assistant").write(answer)


    if got_result:
        if images:
            st.subheader("ðŸ–¼ Ð—Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ Ð·Ñ– ÑÑ‚Ð°Ñ‚Ñ‚Ñ–")
            cols = st.columns(len(images))

            for i, img_url in enumerate(images):
                try:
                    response = requests.get(img_url, timeout=5)
                    img = Image.open(BytesIO(response.content))
                    cols[i].image(img, use_container_width=True, caption=title[:40])
                except:
                    cols[i].image(img_url, use_container_width=True)

        st.subheader("ðŸ“„ Ð”Ð¶ÐµÑ€ÐµÐ»Ð¾ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ–")
        st.markdown(f"**[{title}]({url})**")
        st.write(f"Ð”Ð°Ñ‚Ð°: {date}")
        st.write(f"Ð ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ñ–ÑÑ‚ÑŒ: {score * 100}%")

        with st.expander("ðŸ“– Ð§Ð¸Ñ‚Ð°Ñ‚Ð¸ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚ ÑÑ‚Ð°Ñ‚Ñ‚Ñ–"):
            st.write(text[:1000] + "..." if len(text) > 1000 else text)

    # images = []
    # got_result = True
    # context = ""
    # best_article = None
    # results = []
